ðŸš¨ `test_strategy` is part of LlavaModel.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/home/zhangyichi/miniconda3/envs/eval_new/lib/python3.10/site-packages/transformers/models/llava/modeling_llava.py.
ðŸš¨ `test_strategy` is part of LlavaForConditionalGeneration.forward's signature, but not documented. Make sure to add it to the docstring of the function in /data/home/zhangyichi/miniconda3/envs/eval_new/lib/python3.10/site-packages/transformers/models/llava/modeling_llava.py.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 19.67it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 26.97it/s]
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
left
Model llava-1.5-7b initialized.
Task gpqa initialized.
  0%|          | 0/112 [00:00<?, ?it/s]text_prompt:['USER: <image>\nWhat is the correct answer to this question: A large gene has dozens of exons, of which the central ones code for folded triple helical repeats that connect the cytoskeleton with sarcolemma and extracellular space. Each exon usually codes for one folded triple alpha helix. The most common mutations of the gene are central exon deletions that create out-of-frame peptides and progressive degenerative organ waste. A solution is to deliver a Morpholino that recognizes the 5\' end of the out-of-frame exon in pre-mRNA. The molecule prevents binding of the spliceosome and creates exon skipping and in-frame joining. Several missing exons are well tolerated by an organism. Which structure below is not involved in the proposed therapy?\n\nChoices:\n(A) antisense\n(B) lariat\n(C) polyA tail\n(D) R-loops\n\nFormat your response as follows: "The correct answer is (insert answer here)" ASSISTANT:', 'USER: <image>\nWhat is the correct answer to this question: Two quantum states with energies E1 and E2 have a lifetime of 10^-9 sec and 10^-8 sec, respectively. We want to clearly distinguish these two energy levels. Which one of the following options could be their energy difference so that they can be clearly resolved?\n\n\nChoices:\n(A) 10^-11 eV\n(B) 10^-8 eV\n\n(C) 10^-4 eV\n(D) 10^-9 eV\n\nFormat your response as follows: "The correct answer is (insert answer here)" ASSISTANT:', 'USER: <image>\nWhat is the correct answer to this question: trans-cinnamaldehyde was treated with methylmagnesium bromide, forming product 1.\n\n1 was treated with pyridinium chlorochromate, forming product 2.\n\n3 was treated with (dimethyl(oxo)-l6-sulfaneylidene)methane in DMSO at elevated temperature, forming product 3.\n\nhow many carbon atoms are there in product 3?\n\nChoices:\n(A) 10\n(B) 14\n(C) 12\n(D) 11\n\nFormat your response as follows: "The correct answer is (insert answer here)" ASSISTANT:', 'USER: <image>\nWhat is the correct answer to this question: how many of the following compounds exhibit optical activity?\n1-methyl-4-(prop-1-en-2-yl)cyclohex-1-ene\n2,3,3,3-tetrafluoroprop-1-ene\ndi(cyclohex-2-en-1-ylidene)methane\n5-(5-methylhexan-2-ylidene)cyclopenta-1,3-diene\n3-(2-methylbut-1-en-1-ylidene)cyclohex-1-ene\n[1,1\'-biphenyl]-3,3\'-diol\n8,8-dichlorobicyclo[4.2.0]octan-7-one\ncyclopent-2-en-1-one\n\nChoices:\n(A) 5\n(B) 3\n(C) 4\n(D) 6\n\nFormat your response as follows: "The correct answer is (insert answer here)" ASSISTANT:']
Layer 0, Head 0 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 1 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 2 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 3 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 4 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 5 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 6 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 7 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 8 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 9 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 10 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 11 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 12 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 13 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 14 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 15 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 16 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 17 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 18 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 19 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 20 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 21 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 22 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 23 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 24 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 25 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 26 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 27 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 28 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 29 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 30 attention shape: torch.Size([4, 32, 828, 828])
Layer 0, Head 31 attention shape: torch.Size([4, 32, 828, 828])
Layer 1, Head 0 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 1 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 2 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 3 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 4 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 5 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 6 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 7 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 8 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 9 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 10 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 11 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 12 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 13 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 14 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 15 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 16 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 17 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 18 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 19 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 20 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 21 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 22 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 23 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 24 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 25 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 26 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 27 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 28 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 29 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 30 attention shape: torch.Size([4, 32, 1, 829])
Layer 1, Head 31 attention shape: torch.Size([4, 32, 1, 829])
Layer 2, Head 0 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 1 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 2 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 3 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 4 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 5 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 6 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 7 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 8 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 9 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 10 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 11 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 12 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 13 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 14 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 15 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 16 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 17 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 18 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 19 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 20 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 21 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 22 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 23 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 24 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 25 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 26 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 27 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 28 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 29 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 30 attention shape: torch.Size([4, 32, 1, 830])
Layer 2, Head 31 attention shape: torch.Size([4, 32, 1, 830])
Layer 3, Head 0 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 1 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 2 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 3 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 4 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 5 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 6 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 7 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 8 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 9 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 10 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 11 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 12 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 13 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 14 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 15 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 16 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 17 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 18 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 19 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 20 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 21 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 22 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 23 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 24 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 25 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 26 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 27 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 28 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 29 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 30 attention shape: torch.Size([4, 32, 1, 831])
Layer 3, Head 31 attention shape: torch.Size([4, 32, 1, 831])
Layer 4, Head 0 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 1 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 2 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 3 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 4 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 5 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 6 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 7 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 8 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 9 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 10 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 11 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 12 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 13 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 14 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 15 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 16 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 17 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 18 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 19 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 20 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 21 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 22 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 23 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 24 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 25 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 26 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 27 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 28 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 29 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 30 attention shape: torch.Size([4, 32, 1, 832])
Layer 4, Head 31 attention shape: torch.Size([4, 32, 1, 832])
Layer 5, Head 0 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 1 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 2 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 3 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 4 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 5 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 6 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 7 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 8 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 9 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 10 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 11 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 12 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 13 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 14 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 15 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 16 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 17 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 18 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 19 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 20 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 21 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 22 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 23 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 24 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 25 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 26 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 27 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 28 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 29 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 30 attention shape: torch.Size([4, 32, 1, 833])
Layer 5, Head 31 attention shape: torch.Size([4, 32, 1, 833])
Layer 6, Head 0 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 1 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 2 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 3 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 4 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 5 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 6 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 7 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 8 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 9 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 10 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 11 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 12 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 13 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 14 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 15 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 16 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 17 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 18 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 19 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 20 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 21 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 22 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 23 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 24 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 25 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 26 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 27 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 28 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 29 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 30 attention shape: torch.Size([4, 32, 1, 834])
Layer 6, Head 31 attention shape: torch.Size([4, 32, 1, 834])
Layer 7, Head 0 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 1 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 2 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 3 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 4 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 5 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 6 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 7 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 8 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 9 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 10 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 11 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 12 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 13 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 14 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 15 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 16 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 17 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 18 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 19 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 20 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 21 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 22 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 23 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 24 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 25 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 26 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 27 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 28 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 29 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 30 attention shape: torch.Size([4, 32, 1, 835])
Layer 7, Head 31 attention shape: torch.Size([4, 32, 1, 835])
Layer 8, Head 0 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 1 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 2 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 3 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 4 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 5 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 6 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 7 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 8 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 9 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 10 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 11 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 12 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 13 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 14 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 15 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 16 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 17 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 18 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 19 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 20 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 21 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 22 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 23 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 24 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 25 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 26 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 27 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 28 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 29 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 30 attention shape: torch.Size([4, 32, 1, 836])
Layer 8, Head 31 attention shape: torch.Size([4, 32, 1, 836])
Layer 9, Head 0 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 1 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 2 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 3 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 4 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 5 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 6 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 7 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 8 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 9 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 10 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 11 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 12 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 13 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 14 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 15 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 16 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 17 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 18 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 19 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 20 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 21 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 22 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 23 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 24 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 25 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 26 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 27 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 28 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 29 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 30 attention shape: torch.Size([4, 32, 1, 837])
Layer 9, Head 31 attention shape: torch.Size([4, 32, 1, 837])
Layer 10, Head 0 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 1 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 2 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 3 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 4 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 5 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 6 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 7 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 8 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 9 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 10 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 11 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 12 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 13 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 14 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 15 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 16 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 17 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 18 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 19 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 20 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 21 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 22 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 23 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 24 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 25 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 26 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 27 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 28 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 29 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 30 attention shape: torch.Size([4, 32, 1, 838])
Layer 10, Head 31 attention shape: torch.Size([4, 32, 1, 838])
Layer 11, Head 0 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 1 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 2 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 3 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 4 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 5 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 6 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 7 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 8 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 9 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 10 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 11 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 12 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 13 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 14 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 15 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 16 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 17 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 18 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 19 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 20 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 21 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 22 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 23 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 24 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 25 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 26 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 27 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 28 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 29 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 30 attention shape: torch.Size([4, 32, 1, 839])
Layer 11, Head 31 attention shape: torch.Size([4, 32, 1, 839])
Layer 12, Head 0 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 1 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 2 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 3 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 4 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 5 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 6 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 7 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 8 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 9 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 10 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 11 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 12 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 13 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 14 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 15 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 16 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 17 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 18 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 19 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 20 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 21 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 22 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 23 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 24 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 25 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 26 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 27 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 28 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 29 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 30 attention shape: torch.Size([4, 32, 1, 840])
Layer 12, Head 31 attention shape: torch.Size([4, 32, 1, 840])
Layer 13, Head 0 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 1 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 2 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 3 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 4 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 5 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 6 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 7 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 8 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 9 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 10 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 11 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 12 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 13 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 14 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 15 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 16 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 17 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 18 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 19 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 20 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 21 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 22 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 23 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 24 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 25 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 26 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 27 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 28 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 29 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 30 attention shape: torch.Size([4, 32, 1, 841])
Layer 13, Head 31 attention shape: torch.Size([4, 32, 1, 841])
Layer 14, Head 0 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 1 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 2 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 3 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 4 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 5 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 6 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 7 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 8 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 9 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 10 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 11 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 12 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 13 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 14 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 15 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 16 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 17 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 18 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 19 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 20 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 21 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 22 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 23 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 24 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 25 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 26 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 27 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 28 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 29 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 30 attention shape: torch.Size([4, 32, 1, 842])
Layer 14, Head 31 attention shape: torch.Size([4, 32, 1, 842])
Layer 15, Head 0 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 1 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 2 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 3 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 4 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 5 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 6 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 7 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 8 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 9 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 10 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 11 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 12 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 13 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 14 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 15 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 16 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 17 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 18 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 19 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 20 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 21 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 22 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 23 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 24 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 25 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 26 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 27 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 28 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 29 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 30 attention shape: torch.Size([4, 32, 1, 843])
Layer 15, Head 31 attention shape: torch.Size([4, 32, 1, 843])
  0%|          | 0/112 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/data/zhangyichi/yangjingwen/Eval/main.py", line 103, in <module>
    results = pipeline(args)
  File "/data/zhangyichi/yangjingwen/Eval/main.py", line 88, in pipeline
    outputs.extend(model.generate(batch_text, batch_image, do_sample=False, max_new_tokens=task.max_new_tokens))
  File "/data/home/zhangyichi/miniconda3/envs/eval_new/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data/zhangyichi/yangjingwen/Eval/model/llava.py", line 92, in generate
    generation = self.processor.batch_decode(generated_ids_trimmed, skip_special_tokens=True)
  File "/data/home/zhangyichi/miniconda3/envs/eval_new/lib/python3.10/site-packages/transformers/models/llava/processing_llava.py", line 221, in batch_decode
    return self.tokenizer.batch_decode(*args, **kwargs)
  File "/data/home/zhangyichi/miniconda3/envs/eval_new/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 3801, in batch_decode
    return [
  File "/data/home/zhangyichi/miniconda3/envs/eval_new/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 3802, in <listcomp>
    self.decode(
  File "/data/home/zhangyichi/miniconda3/envs/eval_new/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 3841, in decode
    return self._decode(
  File "/data/home/zhangyichi/miniconda3/envs/eval_new/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py", line 682, in _decode
    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)
TypeError: argument 'ids': Can't extract `str` to `Vec`
